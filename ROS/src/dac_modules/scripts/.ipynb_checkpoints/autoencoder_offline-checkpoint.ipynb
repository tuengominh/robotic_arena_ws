{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/robotics20/robotic_arena_ws/ROS/src/cameras_input/robot_captures_processed/'\n",
    "npy_path = '/home/robotics20/robotic_arena_ws/ROS/src/cameras_input/robot_captures_npy/'\n",
    "recimg_path = '/home/robotics20/robotic_arena_ws/ROS/src/dac_modules/recimgs/'\n",
    "model_path = '/home/robotics20/robotic_arena_ws/ROS/src/dac_modules/model/autoencoder_offline.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell to convert .png files to .npy files and resize images for the first time\n",
    "files = os.listdir(img_path)\n",
    "for file in files[:14168]:  # check number of sample\n",
    "    img = cv2.imread(img_path + file)\n",
    "    img = cv2.flip(img, 0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    scale_percent = 84/240  # check size of input images\n",
    "    dim = (int(img.shape[0] * scale_percent), int(img.shape[0] * scale_percent))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    np.save(npy_path + file.replace('.png', '') + '.npy', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 10:52:03.180251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:03.186825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:03.187246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GPU availability\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14168, 84, 84, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load .npy dataset\n",
    "npys = os.listdir(npy_path)\n",
    "data = np.array([np.load(npy_path + npy) for npy in npys])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_shape=(84,84,3)):  \n",
    "    input_img = Input(shape=img_shape)\n",
    "    filter_size = (3, 3)\n",
    "    pooling_size = (2, 2)\n",
    "    \n",
    "    x = Conv2D(16, filter_size, activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D(pooling_size, padding='same')(x)\n",
    "    x = Conv2D(32, filter_size, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pooling_size, padding='same')(x)\n",
    "    x = Conv2D(32, filter_size, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pooling_size, padding='same')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    x = Dense(11*11*32)(x)\n",
    "    x = Reshape((11, 11, 32))(x)\n",
    "\n",
    "    x = Conv2D(32, filter_size, activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D(pooling_size)(x)\n",
    "    x = Conv2D(32, filter_size, activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D(pooling_size)(x)\n",
    "    x = Conv2D(16, filter_size, activation='relu')(x)\n",
    "    x = UpSampling2D(pooling_size)(x)\n",
    "    x = Conv2D(3, filter_size, activation='relu', padding='same')(x)\n",
    "\n",
    "    model = Model(input_img, x) \n",
    "    optimizer = RMSprop(learning_rate=0.0005)  \n",
    "    model.compile(loss='mse', optimizer=optimizer) \n",
    "    model.summary() \n",
    "    # Save offline .h5 model to reload in the future\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 84, 84, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 84, 84, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 42, 42, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 42, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 21, 21, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 11, 11, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3872)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                77460     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3872)              81312     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 22, 22, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 44, 44, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 42, 42, 16)        4624      \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 84, 84, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 84, 84, 3)         435       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,663\n",
      "Trainable params: 196,663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 10:52:19.469089: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-23 10:52:19.469966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:19.470991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:19.471914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:19.822124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:19.822475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:19.822767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-23 10:52:19.823067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7157 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Only run this cell to build the initial autoencoder\n",
    "autoencoder = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs, batch_size):\n",
    "    history = model.fit(data, data, epochs=epochs, batch_size=batch_size)\n",
    "    #error = history.history['loss'][-1]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 10:52:28.310508: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 299908224 exceeds 10% of free system memory.\n",
      "2022-03-23 10:52:28.504199: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 299908224 exceeds 10% of free system memory.\n",
      "2022-03-23 10:52:28.717434: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 299908224 exceeds 10% of free system memory.\n",
      "2022-03-23 10:52:28.848168: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 299908224 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 10:52:30.073882: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886/886 [==============================] - 7s 6ms/step - loss: 2224.3855\n",
      "Epoch 2/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 1167.1383\n",
      "Epoch 3/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 920.5933\n",
      "Epoch 4/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 795.8801\n",
      "Epoch 5/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 714.0987\n",
      "Epoch 6/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 655.5347\n",
      "Epoch 7/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 612.8618\n",
      "Epoch 8/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 578.1920\n",
      "Epoch 9/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 548.5355\n",
      "Epoch 10/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 525.4736\n",
      "Epoch 11/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 503.9008\n",
      "Epoch 12/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 482.6858\n",
      "Epoch 13/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 467.6939\n",
      "Epoch 14/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 454.2477\n",
      "Epoch 15/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 443.7083\n",
      "Epoch 16/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 432.9176\n",
      "Epoch 17/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 424.3308\n",
      "Epoch 18/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 414.9270\n",
      "Epoch 19/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 406.3065\n",
      "Epoch 20/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 397.3842\n",
      "Epoch 21/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 389.9202\n",
      "Epoch 22/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 382.1785\n",
      "Epoch 23/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 372.8649\n",
      "Epoch 24/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 364.2010\n",
      "Epoch 25/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 358.6908\n",
      "Epoch 26/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 353.0124\n",
      "Epoch 27/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 348.1315\n",
      "Epoch 28/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 345.0234\n",
      "Epoch 29/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 339.2509\n",
      "Epoch 30/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 333.7534\n",
      "Epoch 31/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 330.3398\n",
      "Epoch 32/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 327.5595\n",
      "Epoch 33/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 324.2826\n",
      "Epoch 34/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 319.1196\n",
      "Epoch 35/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 318.5977\n",
      "Epoch 36/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 314.2827\n",
      "Epoch 37/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 311.6275\n",
      "Epoch 38/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 309.6024\n",
      "Epoch 39/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 307.1051\n",
      "Epoch 40/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 305.6994\n",
      "Epoch 41/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 303.5576\n",
      "Epoch 42/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 303.4341\n",
      "Epoch 43/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 300.5297\n",
      "Epoch 44/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 297.5831\n",
      "Epoch 45/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 296.7872\n",
      "Epoch 46/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 295.0581\n",
      "Epoch 47/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 294.3858\n",
      "Epoch 48/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 292.2081\n",
      "Epoch 49/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 292.1869\n",
      "Epoch 50/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 290.4511\n",
      "Epoch 51/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 290.3879\n",
      "Epoch 52/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 288.3320\n",
      "Epoch 53/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 286.8802\n",
      "Epoch 54/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 285.6972\n",
      "Epoch 55/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 284.8071\n",
      "Epoch 56/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 284.4435\n",
      "Epoch 57/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 282.1961\n",
      "Epoch 58/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 281.8295\n",
      "Epoch 59/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 280.4262\n",
      "Epoch 60/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 279.0463\n",
      "Epoch 61/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 279.3156\n",
      "Epoch 62/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 277.6108\n",
      "Epoch 63/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 276.1730\n",
      "Epoch 64/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 274.9876\n",
      "Epoch 65/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 275.0497\n",
      "Epoch 66/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 272.9041\n",
      "Epoch 67/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 272.1219\n",
      "Epoch 68/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 272.1456\n",
      "Epoch 69/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 271.8230\n",
      "Epoch 70/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 270.4523\n",
      "Epoch 71/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 268.9396\n",
      "Epoch 72/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 268.4486\n",
      "Epoch 73/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 267.6454\n",
      "Epoch 74/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 266.8231\n",
      "Epoch 75/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 264.8852\n",
      "Epoch 76/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 265.2031\n",
      "Epoch 77/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 263.4869\n",
      "Epoch 78/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 263.0284\n",
      "Epoch 79/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 262.9064\n",
      "Epoch 80/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 263.5842\n",
      "Epoch 81/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 261.7909\n",
      "Epoch 82/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 261.1107\n",
      "Epoch 83/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 260.0970\n",
      "Epoch 84/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 259.7790\n",
      "Epoch 85/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 259.7694\n",
      "Epoch 86/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 257.9434\n",
      "Epoch 87/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 257.7097\n",
      "Epoch 88/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 257.2516\n",
      "Epoch 89/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 256.3220\n",
      "Epoch 90/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 255.4606\n",
      "Epoch 91/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 255.8796\n",
      "Epoch 92/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 254.6469\n",
      "Epoch 93/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 254.1758\n",
      "Epoch 94/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 253.4106\n",
      "Epoch 95/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 252.9906\n",
      "Epoch 96/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 252.4510\n",
      "Epoch 97/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 251.1885\n",
      "Epoch 98/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 250.8325\n",
      "Epoch 99/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 249.9416\n",
      "Epoch 100/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 250.1338\n",
      "Epoch 101/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 249.5633\n",
      "Epoch 102/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 249.0202\n",
      "Epoch 103/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 248.0376\n",
      "Epoch 104/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 247.5094\n",
      "Epoch 105/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 247.8113\n",
      "Epoch 106/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 247.1119\n",
      "Epoch 107/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 246.1101\n",
      "Epoch 108/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 246.3646\n",
      "Epoch 109/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 245.5955\n",
      "Epoch 110/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 244.5808\n",
      "Epoch 111/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 245.1333\n",
      "Epoch 112/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 244.2851\n",
      "Epoch 113/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 243.7033\n",
      "Epoch 114/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 242.7921\n",
      "Epoch 115/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 242.7040\n",
      "Epoch 116/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 241.6094\n",
      "Epoch 117/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 240.5554\n",
      "Epoch 118/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 241.0070\n",
      "Epoch 119/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 240.8883\n",
      "Epoch 120/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 240.0676\n",
      "Epoch 121/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 239.3962\n",
      "Epoch 122/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 239.0044\n",
      "Epoch 123/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 239.0997\n",
      "Epoch 124/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 238.5616\n",
      "Epoch 125/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 238.2698\n",
      "Epoch 126/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 236.6282\n",
      "Epoch 127/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 237.4192\n",
      "Epoch 128/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 236.9805\n",
      "Epoch 129/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 236.9211\n",
      "Epoch 130/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 236.3009\n",
      "Epoch 131/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 235.2794\n",
      "Epoch 132/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 235.9268\n",
      "Epoch 133/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 233.7434\n",
      "Epoch 134/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 235.0677\n",
      "Epoch 135/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 234.3533\n",
      "Epoch 136/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 233.8586\n",
      "Epoch 137/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 234.0671\n",
      "Epoch 138/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 233.2590\n",
      "Epoch 139/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 232.6843\n",
      "Epoch 140/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 232.8118\n",
      "Epoch 141/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 232.1414\n",
      "Epoch 142/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 232.1242\n",
      "Epoch 143/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 231.5603\n",
      "Epoch 144/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 231.6331\n",
      "Epoch 145/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 231.3382\n",
      "Epoch 146/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 230.7023\n",
      "Epoch 147/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 229.6388\n",
      "Epoch 148/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 230.0716\n",
      "Epoch 149/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 229.7689\n",
      "Epoch 150/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 229.4530\n",
      "Epoch 151/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 228.9469\n",
      "Epoch 152/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 228.9877\n",
      "Epoch 153/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 228.1811\n",
      "Epoch 154/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 228.0658\n",
      "Epoch 155/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 228.1268\n",
      "Epoch 156/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 227.6814\n",
      "Epoch 157/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 227.0041\n",
      "Epoch 158/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 226.3011\n",
      "Epoch 159/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 226.6160\n",
      "Epoch 160/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 226.0729\n",
      "Epoch 161/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 225.7226\n",
      "Epoch 162/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 225.8826\n",
      "Epoch 163/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 225.6212\n",
      "Epoch 164/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 224.6247\n",
      "Epoch 165/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 224.4654\n",
      "Epoch 166/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 224.0927\n",
      "Epoch 167/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 223.4700\n",
      "Epoch 168/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 223.3840\n",
      "Epoch 169/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 222.7173\n",
      "Epoch 170/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 222.2979\n",
      "Epoch 171/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 222.0291\n",
      "Epoch 172/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 221.1087\n",
      "Epoch 173/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 220.1680\n",
      "Epoch 174/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 220.8153\n",
      "Epoch 175/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 219.5374\n",
      "Epoch 176/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 219.0267\n",
      "Epoch 177/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 219.2868\n",
      "Epoch 178/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 218.3212\n",
      "Epoch 179/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 218.0255\n",
      "Epoch 180/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 217.7367\n",
      "Epoch 181/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 216.6576\n",
      "Epoch 182/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 215.7244\n",
      "Epoch 183/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 216.0567\n",
      "Epoch 184/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 215.1423\n",
      "Epoch 185/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 215.1945\n",
      "Epoch 186/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 214.2868\n",
      "Epoch 187/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 214.1969\n",
      "Epoch 188/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 213.1892\n",
      "Epoch 189/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 212.9106\n",
      "Epoch 190/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 211.6095\n",
      "Epoch 191/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 211.8897\n",
      "Epoch 192/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886/886 [==============================] - 5s 6ms/step - loss: 211.0978\n",
      "Epoch 193/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 210.6819\n",
      "Epoch 194/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 209.8759\n",
      "Epoch 195/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 209.7058\n",
      "Epoch 196/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 209.1053\n",
      "Epoch 197/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 208.7127\n",
      "Epoch 198/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 207.8557\n",
      "Epoch 199/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 208.1430\n",
      "Epoch 200/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 207.1937\n",
      "Epoch 201/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 206.7013\n",
      "Epoch 202/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 206.3206\n",
      "Epoch 203/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 205.8270\n",
      "Epoch 204/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 205.2910\n",
      "Epoch 205/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 205.2778\n",
      "Epoch 206/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 204.6851\n",
      "Epoch 207/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 204.5255\n",
      "Epoch 208/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 204.6998\n",
      "Epoch 209/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 203.3271\n",
      "Epoch 210/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 203.2689\n",
      "Epoch 211/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 203.1192\n",
      "Epoch 212/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 202.9901\n",
      "Epoch 213/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 202.1960\n",
      "Epoch 214/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 202.0753\n",
      "Epoch 215/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 201.9032\n",
      "Epoch 216/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 201.7208\n",
      "Epoch 217/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 201.3692\n",
      "Epoch 218/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 200.8046\n",
      "Epoch 219/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 200.7622\n",
      "Epoch 220/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 200.5808\n",
      "Epoch 221/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 199.9994\n",
      "Epoch 222/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 199.9940\n",
      "Epoch 223/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 199.2297\n",
      "Epoch 224/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 199.2560\n",
      "Epoch 225/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 199.2596\n",
      "Epoch 226/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 198.1800\n",
      "Epoch 227/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 198.3487\n",
      "Epoch 228/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 197.4520\n",
      "Epoch 229/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 197.8029\n",
      "Epoch 230/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 197.5890\n",
      "Epoch 231/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 197.1929\n",
      "Epoch 232/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 196.9698\n",
      "Epoch 233/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 196.9530\n",
      "Epoch 234/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 196.3584\n",
      "Epoch 235/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 196.0584\n",
      "Epoch 236/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 195.5035\n",
      "Epoch 237/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 195.3456\n",
      "Epoch 238/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 195.5425\n",
      "Epoch 239/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 195.0786\n",
      "Epoch 240/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 194.7231\n",
      "Epoch 241/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 194.1170\n",
      "Epoch 242/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 194.3891\n",
      "Epoch 243/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 193.6860\n",
      "Epoch 244/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 193.8505\n",
      "Epoch 245/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 193.6011\n",
      "Epoch 246/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 193.9366\n",
      "Epoch 247/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 193.2980\n",
      "Epoch 248/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 192.9190\n",
      "Epoch 249/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 192.5890\n",
      "Epoch 250/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.8319\n",
      "Epoch 251/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 192.2725\n",
      "Epoch 252/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.4656\n",
      "Epoch 253/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.7657\n",
      "Epoch 254/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.4240\n",
      "Epoch 255/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.1856\n",
      "Epoch 256/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.4650\n",
      "Epoch 257/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 190.9601\n",
      "Epoch 258/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 191.2004\n",
      "Epoch 259/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 190.6305\n",
      "Epoch 260/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 190.2867\n",
      "Epoch 261/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 190.3728\n",
      "Epoch 262/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 190.4268\n",
      "Epoch 263/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 190.0768\n",
      "Epoch 264/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 189.9847\n",
      "Epoch 265/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 189.8563\n",
      "Epoch 266/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 189.9908\n",
      "Epoch 267/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 189.9707\n",
      "Epoch 268/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 189.1807\n",
      "Epoch 269/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 189.3550\n",
      "Epoch 270/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 188.9166\n",
      "Epoch 271/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 188.8338\n",
      "Epoch 272/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 188.5770\n",
      "Epoch 273/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 188.2455\n",
      "Epoch 274/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 188.1390\n",
      "Epoch 275/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 187.9778\n",
      "Epoch 276/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 187.8172\n",
      "Epoch 277/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 188.2222\n",
      "Epoch 278/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 187.6294\n",
      "Epoch 279/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 187.5415\n",
      "Epoch 280/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 187.0807\n",
      "Epoch 281/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.6587\n",
      "Epoch 282/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.7715\n",
      "Epoch 283/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.4507\n",
      "Epoch 284/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.1430\n",
      "Epoch 285/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.5119\n",
      "Epoch 286/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.3191\n",
      "Epoch 287/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 186.1125\n",
      "Epoch 288/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 185.7669\n",
      "Epoch 289/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 185.6892\n",
      "Epoch 290/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 185.5881\n",
      "Epoch 291/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 185.5451\n",
      "Epoch 292/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 185.3609\n",
      "Epoch 293/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 185.2070\n",
      "Epoch 294/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.9833\n",
      "Epoch 295/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.7904\n",
      "Epoch 296/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.5861\n",
      "Epoch 297/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.1570\n",
      "Epoch 298/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.3039\n",
      "Epoch 299/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.6544\n",
      "Epoch 300/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.3613\n",
      "Epoch 301/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 184.0393\n",
      "Epoch 302/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.9429\n",
      "Epoch 303/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.7138\n",
      "Epoch 304/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.6077\n",
      "Epoch 305/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.4577\n",
      "Epoch 306/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.2699\n",
      "Epoch 307/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.4260\n",
      "Epoch 308/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.3688\n",
      "Epoch 309/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.7624\n",
      "Epoch 310/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 183.2302\n",
      "Epoch 311/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.9241\n",
      "Epoch 312/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.5599\n",
      "Epoch 313/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.9676\n",
      "Epoch 314/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.6117\n",
      "Epoch 315/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.4255\n",
      "Epoch 316/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.5267\n",
      "Epoch 317/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.5138\n",
      "Epoch 318/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.5212\n",
      "Epoch 319/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.3647\n",
      "Epoch 320/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.9951\n",
      "Epoch 321/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.1213\n",
      "Epoch 322/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.2979\n",
      "Epoch 323/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.2461\n",
      "Epoch 324/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.7908\n",
      "Epoch 325/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 182.5434\n",
      "Epoch 326/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.3067\n",
      "Epoch 327/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.0836\n",
      "Epoch 328/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.4933\n",
      "Epoch 329/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.6083\n",
      "Epoch 330/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.3586\n",
      "Epoch 331/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.2165\n",
      "Epoch 332/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.1378\n",
      "Epoch 333/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 180.9157\n",
      "Epoch 334/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 181.5013\n",
      "Epoch 335/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 180.8909\n",
      "Epoch 336/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 180.9202\n",
      "Epoch 337/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 180.5477\n",
      "Epoch 338/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.8948\n",
      "Epoch 339/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 180.3175\n",
      "Epoch 340/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 180.3943\n",
      "Epoch 341/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 180.3415\n",
      "Epoch 342/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.9196\n",
      "Epoch 343/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 179.9968\n",
      "Epoch 344/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.5063\n",
      "Epoch 345/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.5376\n",
      "Epoch 346/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.8611\n",
      "Epoch 347/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.3500\n",
      "Epoch 348/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.4823\n",
      "Epoch 349/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.1871\n",
      "Epoch 350/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.3014\n",
      "Epoch 351/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.4891\n",
      "Epoch 352/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 179.6516\n",
      "Epoch 353/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 179.0350\n",
      "Epoch 354/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.3679\n",
      "Epoch 355/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.5043\n",
      "Epoch 356/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.9349\n",
      "Epoch 357/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.4710\n",
      "Epoch 358/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.4856\n",
      "Epoch 359/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.0312\n",
      "Epoch 360/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.1167\n",
      "Epoch 361/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.2173\n",
      "Epoch 362/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 178.3992\n",
      "Epoch 363/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 177.4194\n",
      "Epoch 364/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 177.2933\n",
      "Epoch 365/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 177.3835\n",
      "Epoch 366/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 177.3953\n",
      "Epoch 367/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 177.0667\n",
      "Epoch 368/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 177.8347\n",
      "Epoch 369/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.6518\n",
      "Epoch 370/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.4351\n",
      "Epoch 371/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.5520\n",
      "Epoch 372/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.7430\n",
      "Epoch 373/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.2230\n",
      "Epoch 374/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.7577\n",
      "Epoch 375/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.2365\n",
      "Epoch 376/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.2952\n",
      "Epoch 377/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.9266\n",
      "Epoch 378/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.8032\n",
      "Epoch 379/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.0991\n",
      "Epoch 380/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.6652\n",
      "Epoch 381/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.7691\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886/886 [==============================] - 5s 6ms/step - loss: 175.7361\n",
      "Epoch 383/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.3293\n",
      "Epoch 384/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.1744\n",
      "Epoch 385/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.7398\n",
      "Epoch 386/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.7567\n",
      "Epoch 387/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.9832\n",
      "Epoch 388/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.5112\n",
      "Epoch 389/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 176.0828\n",
      "Epoch 390/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.6116\n",
      "Epoch 391/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.3593\n",
      "Epoch 392/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 175.3289\n",
      "Epoch 393/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.4313\n",
      "Epoch 394/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.4365\n",
      "Epoch 395/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.1225\n",
      "Epoch 396/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.2807\n",
      "Epoch 397/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.3954\n",
      "Epoch 398/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.5960\n",
      "Epoch 399/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.1683\n",
      "Epoch 400/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.1328\n",
      "Epoch 401/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 174.0934\n",
      "Epoch 402/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.6217\n",
      "Epoch 403/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.7177\n",
      "Epoch 404/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.1968\n",
      "Epoch 405/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.6386\n",
      "Epoch 406/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.9090\n",
      "Epoch 407/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.3570\n",
      "Epoch 408/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.3002\n",
      "Epoch 409/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.8991\n",
      "Epoch 410/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.4374\n",
      "Epoch 411/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 173.4728\n",
      "Epoch 412/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.7370\n",
      "Epoch 413/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.7279\n",
      "Epoch 414/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.2928\n",
      "Epoch 415/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.1161\n",
      "Epoch 416/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.1686\n",
      "Epoch 417/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.5481\n",
      "Epoch 418/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.1762\n",
      "Epoch 419/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.2073\n",
      "Epoch 420/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.4610\n",
      "Epoch 421/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.8412\n",
      "Epoch 422/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.0754\n",
      "Epoch 423/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.0684\n",
      "Epoch 424/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.1716\n",
      "Epoch 425/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.8618\n",
      "Epoch 426/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 172.0251\n",
      "Epoch 427/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.8278\n",
      "Epoch 428/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.4523\n",
      "Epoch 429/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.5288\n",
      "Epoch 430/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.8071\n",
      "Epoch 431/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.5443\n",
      "Epoch 432/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.5005\n",
      "Epoch 433/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.2936\n",
      "Epoch 434/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.1469\n",
      "Epoch 435/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.5207\n",
      "Epoch 436/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.9725\n",
      "Epoch 437/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.3407\n",
      "Epoch 438/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.1080\n",
      "Epoch 439/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.5923\n",
      "Epoch 440/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.9852\n",
      "Epoch 441/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.8333\n",
      "Epoch 442/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.1884\n",
      "Epoch 443/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.6263\n",
      "Epoch 444/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.6812\n",
      "Epoch 445/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.2878\n",
      "Epoch 446/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 171.1045\n",
      "Epoch 447/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.3710\n",
      "Epoch 448/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.5283\n",
      "Epoch 449/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.3882\n",
      "Epoch 450/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.2417\n",
      "Epoch 451/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.9991\n",
      "Epoch 452/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.7627\n",
      "Epoch 453/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.0199\n",
      "Epoch 454/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.6793\n",
      "Epoch 455/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.4346\n",
      "Epoch 456/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.4787\n",
      "Epoch 457/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 170.4622\n",
      "Epoch 458/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.2562\n",
      "Epoch 459/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.8391\n",
      "Epoch 460/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.6288\n",
      "Epoch 461/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.4990\n",
      "Epoch 462/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.8823\n",
      "Epoch 463/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.8406\n",
      "Epoch 464/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.2700\n",
      "Epoch 465/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.3521\n",
      "Epoch 466/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.8649\n",
      "Epoch 467/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.1203\n",
      "Epoch 468/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.3389\n",
      "Epoch 469/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.1454\n",
      "Epoch 470/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.4398\n",
      "Epoch 471/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.0898\n",
      "Epoch 472/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.1561\n",
      "Epoch 473/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.1261\n",
      "Epoch 474/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.9056\n",
      "Epoch 475/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.0112\n",
      "Epoch 476/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.3127\n",
      "Epoch 477/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.8711\n",
      "Epoch 478/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 169.0911\n",
      "Epoch 479/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.5006\n",
      "Epoch 480/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.5796\n",
      "Epoch 481/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.5183\n",
      "Epoch 482/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.6766\n",
      "Epoch 483/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.1667\n",
      "Epoch 484/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.7604\n",
      "Epoch 485/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.6057\n",
      "Epoch 486/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.1740\n",
      "Epoch 487/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.9855\n",
      "Epoch 488/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.5169\n",
      "Epoch 489/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 168.0033\n",
      "Epoch 490/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.6742\n",
      "Epoch 491/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.1987\n",
      "Epoch 492/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 167.7487\n",
      "Epoch 493/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.0625\n",
      "Epoch 494/500\n",
      "886/886 [==============================] - 6s 7ms/step - loss: 168.3566\n",
      "Epoch 495/500\n",
      "886/886 [==============================] - 6s 6ms/step - loss: 168.0492\n",
      "Epoch 496/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.9742\n",
      "Epoch 497/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 167.8611\n",
      "Epoch 498/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 167.9609\n",
      "Epoch 499/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 167.6209\n",
      "Epoch 500/500\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 168.1030\n"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder = keras.models.load_model(model_path)\n",
    "history = train(autoencoder, data, 5000, 16)\n",
    "autoencoder.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fccdc2b6b50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot errors\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(prototype, indx):\n",
    "    rec_img = prototype[0]\n",
    "    rec_img = cv2.cvtColor(rec_img, cv2.COLOR_RGB2BGR)\n",
    "    img_name = recimg_path + str(indx) + '.png'\n",
    "    cv2.imwrite(img_name, rec_img)\n",
    "    #img_name = recimg_path + str(indx) + '.npy'\n",
    "    #np.save(img_name, rec_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img, indx):\n",
    "    #m = Model(inputs=model.inputs, outputs=model.get_layer('dense').output)\n",
    "    #prototype = m.predict(np.expand_dims(img, axis=0))\n",
    "    prototype = model.predict(img.reshape((1,84,84,3)))\n",
    "    save_image(prototype, indx)\n",
    "    return prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicted/reconstructed images\n",
    "autoencoder = keras.models.load_model(model_path)\n",
    "for npy in npys:\n",
    "    predict(autoencoder, np.load(npy_path + npy), npy.replace('.npy', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision inputs vs. reconstructed images\n",
    "indx = 835\n",
    "\n",
    "#plt.imshow(mpimg.imread(img_path + str(indx) + '.png'))\n",
    "plt.imshow(np.load(npy_path + str(indx) + '.npy'))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mpimg.imread(recimg_path + str(indx) + '.png'))\n",
    "#plt.imshow(np.load(recimg_path + str(indx) + '.npy'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
